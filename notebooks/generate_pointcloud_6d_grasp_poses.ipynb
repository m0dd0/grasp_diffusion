{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrucutred version of the same named script in the `scripts` directory. Used to understand the code better and analysze whats going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing module 'gym_37' (/home/moritz/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_37.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /home/moritz/Documents/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moritz/miniconda3/envs/alr/envs/se3dif_env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.13.1+cu116\n",
      "Device count 1\n",
      "/home/moritz/Documents/isaacgym/python/isaacgym/_bindings/src/gymtorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/moritz/.cache/torch_extensions/py37_cu116 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/moritz/.cache/torch_extensions/py37_cu116/gymtorch/build.ninja...\n",
      "Building extension module gymtorch...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module gymtorch...\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# isaac gym has to be imported before torch\n",
    "from isaac_evaluation.grasp_quality_evaluation import GraspSuccessEvaluator\n",
    "\n",
    "import scipy.spatial.transform\n",
    "import numpy as np\n",
    "from se3dif.datasets import AcronymGraspsDirectory\n",
    "from se3dif.models.loader import load_model\n",
    "from se3dif.samplers import ApproximatedGrasp_AnnealedLD, Grasp_AnnealedLD\n",
    "from se3dif.utils import to_numpy, to_torch\n",
    "from se3dif.visualization import grasp_visualization\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRASPS = 10               # argument values from README: 10,10,10. default in argparse: 200\n",
    "OBJ_ID = 0                  # argument values from README: 0,10,12.  default in argparse: 0\n",
    "obj_class = \"ScrewDriver\"   # argument values from README: 'ScrewDriver','grasp_dif_mugs','Mug'. default in argparse: \"Laptop\"\n",
    "n_envs = 30                 # hardcoded in the code with default value 30 in __main__\n",
    "device = \"cuda:0\"           # argumant values from README: n.a., n.a., n.a. default in argparse: \"cuda:0\"\n",
    "EVAL_SIM = False            # argument values from README: n.a., n.a., n.a. default in argparse: False\n",
    "model = \"grasp_dif_multi\"   # argument values from README: n.a., 'grasp_dif_mugs', n.a. default in argparse: 'grasp_dif_multi'\n",
    "batch = 10                  # hardcoded in code with default value 10 in get_approximated_grasp_diffusion_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_pointcloud(obj_id=0, obj_class='Mug'):\n",
    "#    ...\n",
    "# P, mesh, trans, rot_quad = sample_pointcloud(obj_id, obj_class)\n",
    "\n",
    "# get mesh of object and sample pointcloud\n",
    "acronym_grasps = AcronymGraspsDirectory(data_type=obj_class)\n",
    "mesh = acronym_grasps.avail_obj[OBJ_ID].load_mesh()\n",
    "P = mesh.sample(1000)\n",
    "\n",
    "# get a random rotation and apply it to the pointcloud\n",
    "sampled_rot = scipy.spatial.transform.Rotation.random()\n",
    "rot = sampled_rot.as_matrix()\n",
    "rot_quat = sampled_rot.as_quat()\n",
    "\n",
    "P = np.einsum('mn,bn->bm', rot, P)\n",
    "P *= 8.\n",
    "P_mean = np.mean(P, 0)\n",
    "P += -P_mean\n",
    "\n",
    "# recenter the pointcloud (??)\n",
    "H = np.eye(4)\n",
    "H[:3,:3] = rot\n",
    "mesh.apply_transform(H)\n",
    "mesh.apply_scale(8.) # ???\n",
    "H = np.eye(4)\n",
    "H[:3,-1] = -P_mean\n",
    "mesh.apply_transform(H)\n",
    "translational_shift = copy.deepcopy(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  [-0.17545176 -0.3779445  -0.08673489] [0.13879214 0.78269891 0.07418472] (1000, 3) float64 [ 1.98521755e-17 -1.86156646e-16 -2.81719092e-18]\n",
      "mesh:  <class 'trimesh.base.Trimesh'> [-0.17623076 -0.37902653 -0.08859384] [0.1414876  0.78394328 0.07529752] (789, 3) float64 [-0.0091348   0.03828545 -0.00031418]\n",
      "translational shift [[ 1.          0.          0.         -0.03230393]\n",
      " [ 0.          1.          0.          0.15495371]\n",
      " [ 0.          0.          1.          0.00696618]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "rotational quat [ 0.29161696 -0.66390253  0.67454917  0.13847884]\n"
     ]
    }
   ],
   "source": [
    "print(\"P: \", P.min(0), P.max(0), P.shape, P.dtype, P.mean(0))\n",
    "print(\"mesh: \", type(mesh), mesh.vertices.min(0), mesh.vertices.max(0), mesh.vertices.shape, mesh.vertices.dtype, mesh.vertices.mean(0))\n",
    "print(\"translational shift\" , translational_shift)\n",
    "print(\"rotational quat\" , rot_quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator, model = get_approximated_grasp_diffusion_field(P, args, device)\n",
    "# def get_approximated_grasp_diffusion_field(p, args, device='cpu'):\n",
    "\n",
    "## Load model\n",
    "model_args = {\n",
    "    'device': device,\n",
    "    'pretrained_model': model\n",
    "}\n",
    "model = load_model(model_args)\n",
    "\n",
    "context = to_torch(P[None,...], device)\n",
    "model.set_latent(context, batch=batch)\n",
    "\n",
    "########### 2. SET SAMPLING METHOD #############\n",
    "generator = Grasp_AnnealedLD(model, batch=batch, T=70, T_fit=50, k_steps=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator:  <class 'se3dif.samplers.grasp_samplers.Grasp_AnnealedLD'>\n",
      "model:  <class 'se3dif.models.grasp_dif.GraspDiffusionFields'>\n"
     ]
    }
   ],
   "source": [
    "print(\"generator: \", type(generator))\n",
    "print(\"model: \", type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = generator.sample()\n",
    "\n",
    "H_grasp = copy.deepcopy(H)\n",
    "# counteract the translational shift of the pointcloud (as the spawned model in simulation will still have it)\n",
    "H_grasp[:, :3, -1] = (H_grasp[:, :3, -1] - torch.as_tensor(translational_shift[:3,-1],device=device)).float()\n",
    "H[..., :3, -1] *=1/8.\n",
    "H_grasp[..., :3, -1] *=1/8.\n",
    "\n",
    "## Visualize results ##\n",
    "\n",
    "vis_H = H.squeeze()\n",
    "P *=1/8\n",
    "mesh = mesh.apply_scale(1/8)\n",
    "grasp_visualization.visualize_grasps(to_numpy(H), p_cloud=P, mesh=mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (EVAL_SIM):\n",
    "    ## Evaluate Grasps in Simulation##\n",
    "    num_eval_envs = 10\n",
    "    evaluator = GraspSuccessEvaluator(obj_class, n_envs=num_eval_envs, idxs=[args.obj_id] * num_eval_envs, viewer=True, device=device, \\\n",
    "                                        rotations=[rot_quad]*num_eval_envs, enable_rel_trafo=False)\n",
    "    succes_rate = evaluator.eval_set_of_grasps(H_grasp)\n",
    "    print('Success cases : {}'.format(succes_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se3dif_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
