{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrucutred version of the same named script in the `scripts` directory. Used to understand the code better and analysze whats going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Tuple\n",
    "\n",
    "# isaac gym has to be imported before torch\n",
    "from isaac_evaluation.grasp_quality_evaluation import GraspSuccessEvaluator\n",
    "import trimesh\n",
    "\n",
    "import scipy.spatial.transform\n",
    "import numpy as np\n",
    "from se3dif.datasets import AcronymGraspsDirectory\n",
    "from se3dif.models.loader import load_model\n",
    "from se3dif.samplers import ApproximatedGrasp_AnnealedLD, Grasp_AnnealedLD\n",
    "from se3dif.utils import to_numpy, to_torch\n",
    "from se3dif.visualization import grasp_visualization\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRASPS = 10               # argument values from README: 10,10,10. default in argparse: 200\n",
    "OBJ_ID = 0                  # argument values from README: 0,10,12.  default in argparse: 0\n",
    "OBJ_CLASS = \"ScrewDriver\"   # argument values from README: 'ScrewDriver','grasp_dif_mugs','Mug'. default in argparse: \"Laptop\"\n",
    "N_ENVS = 30                 # hardcoded in the code with default value 30 in __main__\n",
    "DEVICE = \"cuda:0\"           # argumant values from README: n.a., n.a., n.a. default in argparse: \"cuda:0\"\n",
    "EVAL_SIM = False            # argument values from README: n.a., n.a., n.a. default in argparse: False\n",
    "MODEL = \"grasp_dif_multi\"   # argument values from README: n.a., 'grasp_dif_mugs', n.a. default in argparse: 'grasp_dif_multi'\n",
    "BATCH = 10                  # hardcoded in code with default value 10 in get_approximated_grasp_diffusion_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_data(\n",
    "    obj_id: int, obj_class: str\n",
    ") -> Tuple[\"NpArray[3, N]\", trimesh.Trimesh, \"NpArray[4, 4]\", \"NpArray[4, 4]\"]:\n",
    "    \"\"\"Load the mesh of the specified object and sample a pointcloud from it.\n",
    "    The pointcloud and the mesh is rotated randomly, scaled by 8 and made zero mean.\n",
    "\n",
    "    Args:\n",
    "        obj_id (int): The id of the object to load.\n",
    "        obj_class (str): The class of the object to load.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[\"NpArray[3, N]\", trimesh.Trimesh, \"NpArray[4, 4]\", \"NpArray[4]\"]: The pointcloud, \n",
    "            the mesh, the homogenaous transformation matrix of the rotation and the homogeneous\n",
    "            transformation matrix of the translation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get mesh of object and sample pointcloud\n",
    "    acronym_grasps = AcronymGraspsDirectory(data_type=obj_class)\n",
    "    mesh = acronym_grasps.avail_obj[obj_id].load_mesh()\n",
    "    pointcloud = mesh.sample(1000)\n",
    "\n",
    "    # get a random rotation\n",
    "    H_rot = np.eye(4)\n",
    "    H_rot[:3, :3] = scipy.spatial.transform.Rotation.random().as_matrix()\n",
    "\n",
    "    # apply the rotation to the pointcloud and mesh\n",
    "    pointcloud = np.einsum(\"mn,bn->bm\", H_rot[:3,:3], pointcloud)\n",
    "    mesh.apply_transform(H_rot)\n",
    "\n",
    "    # scale the pointcloud and mesh\n",
    "    pointcloud *= 8.0\n",
    "    mesh.apply_scale(8.0)\n",
    "    \n",
    "    # get the translation to make the pointcloud and mesh zero mean\n",
    "    H_trans = np.eye(4)\n",
    "    H_trans[:3, -1] = -np.mean(pointcloud, 0)\n",
    "    pointcloud += H_trans[:3, -1]\n",
    "    mesh.apply_transform(H_trans)\n",
    "\n",
    "    return pointcloud, mesh, H_rot, H_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_grasp_generator(pointcloud, model):\n",
    "    model.set_latent(to_torch(pointcloud[None, ...], DEVICE), batch=BATCH)\n",
    "    generator = Grasp_AnnealedLD(\n",
    "        model, batch=BATCH, T=70, T_fit=50, k_steps=2, device=DEVICE\n",
    "    )\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_grasp(H_grasp,pointcloud,mesh,H_trans):\n",
    "    # counteract the translational shift of the pointcloud (as the spawned model in simulation will still have it)\n",
    "    H_grasp[:, :3, -1] = (H_grasp[:, :3, -1] - torch.as_tensor(H_trans[:3,-1],device=DEVICE)).float()\n",
    "    \n",
    "    H_grasp[..., :3, -1] *=1/8.\n",
    "\n",
    "    # Visualize results\n",
    "    pointcloud *=1/8\n",
    "    mesh = mesh.apply_scale(1/8)\n",
    "    scene = grasp_visualization.visualize_grasps(Hs=to_numpy(H_grasp), p_cloud=pointcloud, mesh=mesh, show=False)\n",
    "\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointcloud, mesh, H_rot, H_trans = get_object_data(OBJ_ID, OBJ_CLASS)\n",
    "model = load_model({\"device\": DEVICE, \"pretrained_model\": MODEL})\n",
    "generator = get_fitted_grasp_generator(pointcloud, model)\n",
    "H_grasp = generator.sample() # torch.Size([10, 4, 4])\n",
    "# scene = visualize_grasp(H_grasp,pointcloud,mesh, H_trans)\n",
    "# scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.zeros(H_grasp.shape[0])\n",
    "\n",
    "## Grips\n",
    "grips = []\n",
    "for k in range(H_grasp.shape[0]):\n",
    "    H = H_grasp[k,...]\n",
    "\n",
    "    c = color[k]\n",
    "    c_vis = [0, 0, int(c*254)]\n",
    "\n",
    "    grips.append(\n",
    "        grasp_visualization.create_gripper_marker(color=c_vis, scale=1).apply_transform(H)\n",
    "    )\n",
    "\n",
    "## Visualize grips and the object\n",
    "if mesh is not None:\n",
    "    scene = trimesh.Scene([mesh]+ grips)\n",
    "\n",
    "scene.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (EVAL_SIM):\n",
    "#     ## Evaluate Grasps in Simulation##\n",
    "#     num_eval_envs = 10\n",
    "#     evaluator = GraspSuccessEvaluator(OBJ_CLASS, n_envs=num_eval_envs, idxs=[args.obj_id] * num_eval_envs, viewer=True, device=DEVICE, \\\n",
    "#                                         rotations=[rot_quad]*num_eval_envs, enable_rel_trafo=False)\n",
    "#     succes_rate = evaluator.eval_set_of_grasps(H_grasp)\n",
    "#     print('Success cases : {}'.format(succes_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se3dif_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
